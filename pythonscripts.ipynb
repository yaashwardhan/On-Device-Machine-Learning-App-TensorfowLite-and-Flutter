{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Untitled2.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMjqE22Bu5IS3NSvOUU3suL"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"bCqz5BzObkoS"},"source":["import tensorflow as tf\n","import os #for file management"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HiJ3-XUibnEu"},"source":["base_dir = './dataset/train' #setting the base_dir variable to the location of the dataset containing the images"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9RDjXSRFbnHH"},"source":["#now we will do some preprocessing, i.e we are preparing the raw data to make it suitable for a building and training models\n","IMAGE_SIZE = 224 #image size that we are going to set the images in the dataset to.\n","BATCH_SIZE = 64 #the number of images we are inputting into the neural network at once.\n","\n","datagen = tf.keras.preprocessing.image.ImageDataGenerator( #preprocessing our image\n","    rescale = 1./255, #firstly, rescaling it to 1/255 which will make the file size smaller, hence reducing the training time\n","    validation_split=0.2 #secondly, normally a dataset has a test set and a training set, \n","    #validation set is normally to test our neural network,which would give us a measure of accuracy on how well the neural network will do on the predictions.\n","    #here we are telling keras to use 20% for validation and 80% training\n",")\n","\n","train_generator = datagen.flow_from_directory( #training generator\n","    base_dir, #the directory having the fruits and vegetable photos\n","    target_size=(IMAGE_SIZE, IMAGE_SIZE),  #converting images to 224 by 224\n","    batch_size = BATCH_SIZE, #images getting inputed into the neural network through each epoch or each step\n","    subset='training' #the name we will call it\n",")\n","val_generator = datagen.flow_from_directory(  #validation generator\n","    base_dir, \n","    target_size=(IMAGE_SIZE, IMAGE_SIZE),\n","    batch_size=BATCH_SIZE,\n","    subset='validation'\n",")\n","#So as we can see from below, our training generator dataset 2872 images and the validation generator dataset has 709 images"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"L8v9pUx0bnJh"},"source":["#Next we have to create a labels.txt file that will hold all our labels (important for Flutter)\n","print(train_generator.class_indices) #prints every single key and class of that dataset\n","labels = '\\n'.join(sorted(train_generator.class_indices.keys())) #print all these keys as a list of labels into a text file called labels.txt\n","with open('labels.txt', 'w') as f: #writes to the labels.txt file, and if it doesnt exists, it creates one, and if it does exist, it will overrite it. (thats what 'w' is for)\n","    f.write(labels)\n","\n","#preprocessing of raw data is hence complete and now its time to build our neural network"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6Zwet3CbbnL-"},"source":["#building a neural network using transfer learning method where we take a pretrained neural network called MobileNetV2 which is a convolutional neural network architecture that seeks to perform well on mobile devices and can predict up to 80 different classes\n","#we are going to have a base model on top of which we are going to add pre trained neural network to have it predict the classes we want\n","IMG_SHAPE = (IMAGE_SIZE, IMAGE_SIZE, 3) \n","base_model = tf.keras.applications.MobileNetV2( #grabbing pretrained neural network of choice\n","    input_shape=IMG_SHAPE,\n","    include_top=False, #this will freeze all the weights, because we dont have to retrain and change the weights, instead just add on to the MobileNetV2 CNN, so it clasiffies 5 classes instead of 80\n","    weights='imagenet'\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GuYklq4SbnOU"},"source":["base_model.trainable=False #this freezes all the neurons for our base model\n","model = tf.keras.Sequential([ #neural networks act in a sequence of layers, so we add layers as we want\n","  base_model,\n","  tf.keras.layers.Conv2D(32,3, activation = 'relu'), #This layer creates a convolution kernel that is convolved with the layer input to produce a tensor of outputs. Bascially, it trying to understand the patterns of the image\n","  tf.keras.layers.Dropout(0.2), #This layer prevents Neural Networks from Overfitting, i.e being too precise to a point where the NN is only able to recognize images that are present in the dataset\n","  tf.keras.layers.GlobalAveragePooling2D(), #This layer calculates the average output of each feature map in the previous layer, thus reducing the data significantly and preparing the model for the final layer\n","  tf.keras.layers.Dense(36, #no.of classes\n","                        activation='softmax')\n","])\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bIww3EHpbnQn"},"source":["model.compile(\n","    optimizer=tf.keras.optimizers.Adam(), #Adam is a popular optimiser, designed specifically for training deep neural networks\n","    loss='categorical_crossentropy', \n","    metrics=['accuracy']\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"c-WUCFsPbnS6"},"source":["epochs = 10 #higher the epochs, more accurate is the NN, however it could cause Overfitting, if too high\n","history = model.fit(\n","    train_generator, \n","    epochs = epochs, \n","    validation_data=val_generator\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bMJhJkpZb5dK"},"source":["#now that we have our neural network trained with tensorflow and keras, we can export it \n","saved_model_dir = '' #means current directory\n","tf.saved_model.save(model, saved_model_dir) #saves to the current directory\n","\n","converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir) \n","tflite_model = converter.convert() #converts our model into a .tflite model which flutter uses for ondevice machine learning\n","\n","with open('model.tflite', 'wb') as f: #to write the converted model into a file, written as binary so add 'wb' instead of 'w'\n","  f.write(tflite_model)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"y1nznkgIb5fW"},"source":["#use below codes to download files locally if using google colab\n","#from google.colab import files\n","#files.download('model.tflite')\n","#files.download('labels.txt')"],"execution_count":null,"outputs":[]}]}